\section{Implementation} \label{sec:impl}
The accompanying git repository contains more than one implementation, or \textit{variant}, of Dinur's original algorithm. These variants are divided into two C implementations and a prototype SageMath implementation. C function declarations can be found in the \texttt{inc/} folder and other code can be found under \texttt{src/}. These implementations, alongside everything else worked on for this thesis, can be found at 
\begin{center}
    \url{https://github.com/Moggel12/MQ-Solver}.
\end{center}

For alternative implementations of some of the procedures described in \cref{sec:prereq}, see \cite{ches-2010-23990}, \cite{cryptoeprint:2013/436}, and \cite{crypto-2022-32130}.

\subsection{Platform and architecture}

This section describes the platform and architecture used for building, testing, and benchmarking the programs written for this thesis. For a description of the actual implementation see the previous subsections.

The compiler and operating systems used in this thesis are GCC and GNU/Linux. Therefore, running a non-GNU/Linux operating system or compiling using a non-GCC C/C++ compiler is not guaranteed to work. For running the codebase in a containerized environment, refer to the accompanying Dockerfile. Although most modern CISC CPUs are based on 64-bit instructions, compilation targets also exist for 32, 16, and 8-bit platforms (or registers).

Some of the most important instruction sets present today, other than the common CPU instructions like addition and move/load, are SIMD (Single Instruction Multiple Data) instruction sets. Three such instruction sets are SSE2 (Steaming SIMD Extensions), AVX (Advanced Vector Extensions), and AVX2. These are all present on modern x86 CPUs, however, some also include the AVX512 instruction set. The compilation targets in this thesis only support up to AVX/AVX2. These instruction sets allow using 128-bit and 256-bit vector registers for computation on multiple data elements in one instruction. AVX512 enables further support for 256-bit vector registers while also supporting 512-bit vector registers.

The AVX/AVX2 instructions operate on the \texttt{ymm}[0-15] 256-bit registers, while the SSE2 instructions operate on the \texttt{xmm}[0-15] 128-bit registers. This instruction sets support loads/stores, bit-wise operations, addition, subtraction, shuffling, and much more. The data packed into a vector may be both floating point data or integer data, however, in this project only integer data is necessary. The integer sizes packed into vector registers may also vary, depending on the needs. As will become clear when discussing optimizations to the C code, this project either uses 8- or 16-bit integers. To examine the full extent of these instruction sets, as well as their latencies and throughputs, refer to the respective documentation at the CPU manufacturer (such as Intel or AMD).

The parts of the code that make use of vector instructions do not use GCCs inline assembly or separate assembly files. Instead, the programs using vector instructions make use of GCC intrinsic functions for these instruction sets, i.e. those documented in \cite{IntelIntr}. How these instructions are used can be read in \cref{sec:impl:opt:parallel}.

Finally, the implementations can also be told to use most of the resources present on multicore platforms. Currently, the code only supports allocating a power-of-two amount of CPU cores, so certain CPUs may not be fully utilized. The code also does not distinguish between the \textit{performance} and \textit{efficiency} type cores found in certain contemporary CPUs.

\subsection{SageMath code} \label{sec:impl:sage}
As was implied earlier, the SageMath implementation of Dinur's algorithm works mostly as a prototype or testing ground for the C implementation. Some optimizations have been tested in this version of the code, prior to it being implemented in C, however, these optimizations worked on an algorithmic level more than on a machine level.  This prototype allowed for approximating the bottleneck areas of the algorithm while essentially also working as a proof-of-concept for using Dinur's algorithm in practice. These approximations of course were rougher in some areas than others, due to the overhead imposed by SageMath and Python.

The prototype implements the three procedures described by Dinur in \cite{eurocrypt-2021-30841}, more or less described as the pseudo-code is presented. The three main procedures described by Dinur can be found in \texttt{src/sage/dinur.sage} with some accompanying convenience and test functions. A bit-sliced version of the FES procedure, described in \cite{ches-2010-23990} and \cref{sec:prereq:fes}, for quadratic polynomials can be found in \texttt{src/sage/fes.sage}. This implementation is not as heavily optimized as those in \cite{ches-2010-23990} and \cite{cryptoeprint:2013/436}, simply due to the SageMath-induced overhead counteracting fine-adjusted optimizations. The prototype code also introduces a FES-based recovery procedure, acting as an alternative to the Möbius Transform originally described by Dinur (see \cref{sec:ext}). The Möbius Transform was implemented in \texttt{src/sage/mob\_new.sage} and allows for a \textit{sparse}-transform used for interpolating the $U$-polynomials. This implementation is rather naive as it interpolates these polynomials \textit{symbolically} using the polynomial classes from SageMath. The choice of switching between FES-based interpolation and using the Möbius transform is a simple boolean switch in the \texttt{solve()} and \texttt{output\_potentials()} functions in \texttt{src/sage/dinur.sage}.

The tests for the SageMath procedures can be found in the same file as the procedure they test. This is simply due to the prototype nature of the SageMath code, therefore the SageMath code is primarily used for verification of the C-code. As references to practical implementations of these procedures are sparse, the SageMath code was rather important as it eliminated the normal headaches of working in C and allowed for a more theory-near approach. Considering that SageMath has procedures built-in for working with polynomials, matrices and rings, it was a very important stepping stone towards a C implementation. Once the prototype was finished, implementing the C code was easier as most of the algorithmic ideas had already been exercised.

Other than the prototype code implemented in SageMath, a \textit{front-end} was also implemented allowing for easier loading systems, generation systems, and calling of the optimized C code. For more on this, see \cref{sec:impl:interface}.

\subsubsection{Dinur's core procedures}
\paragraph{SageMath implementation of \texttt{SOLVE()}.} The top-level \texttt{solve()} procedure can be found in the \texttt{src/sage/dinur.sage} file. To test it, one may call the \texttt{test\_sage\_solve()} function with appropriate parameters. This implementation of Dinur's algorithm tries to mimic the pseudo-code (see \cref{alg:solve}) closely, e.g. by using dictionaries for comparing potential solutions from the current round with those of earlier rounds. However, by close inspection, one might see that there are few differences between the implementation and the pseudo-code still. In the pseudo-code, Dinur parameterizes the variable $n_1$, allowing variation on how it is chosen. The SageMath implementation fixes this to 
$$
    n_1 \approx \lceil \frac{n}{5.4} \rceil.
$$
The choice of fixing $n_1$ to this specific value stems from Dinur's proof of the time complexity of this algorithm. Setting the parameter to approximately $\frac{n}{5.4}$ ensures that the complexity is balanced between the time evaluating the $U$ polynomials and the time taken for computing the evaluations of $\Tilde{\mathcal{P}}_k$ in the set $W^{n - n_1}_{w + 1} \times \{0,1\}^{n_1}$. This can be altered in the SageMath source code itself if necessary, however, here it was kept simple.

Another part of the SageMath code that differs from the source material is its 
\texttt{fes\_recovery} parameter. This parameter handles whether or not to use FES-based recovery, described in \cref{sec:ext:fes_interp}, to recover the $U$ polynomials. The parameter is essentially a boolean switch that tells the \texttt{output\_potentials()} function which implementation is needed. A look at the main loop inside the \texttt{solve()} function shows the last \textit{major} deviance from the pseudo-code of \cref{alg:solve}. Here, instead of allowing the algorithm to run indefinitely the length of the \textit{history} is limited. The limit found here can be changed in \texttt{src/sage/c\_config.py} and defaults to 30.

Generating the matrix $A^{(k)}$ of \cref{alg:solve}, \cref{alg:solve:matrix}, for constructing $\Tilde{\mathcal{P}}_k$ occurs in \texttt{gen\_matrix\_rank\_l()}. Ensuring that matrix $A^{(k)}$ has rank $\ell$ is a simple Las Vegas (algorithmic) approach generating new matrices until one with the needed rank is acquired. The generation of the matrix makes use of the \texttt{rand()} function from the C standard library. The PRNG is seeded in \texttt{solve()} using the constant \texttt{RSEED}, defaulting to 42. The underlying PRNG may be changed in the \texttt{src/sage/c\_config.py} file as well, however, is useful for simplifying the testing of the C implementation.

Now, the way polynomials are represented in the SageMath code is through the built-in (in SageMath) representation of boolean polynomials. As mentioned earlier, this does incur an overhead but will also simplify certain operations, such as generating the system $\Tilde{\mathcal{P}}_k$:
\pylisting{src/sage/dinur.sage}{329}{329}
which also eases the process of computing $w = d_{\Tilde{\mathcal{F}}} - n_1$,
\pylisting{src/sage/dinur.sage}{331}{331}
alongside evaluating the polynomials in the system on candidate solutions:
\pylisting{src/sage/dinur.sage}{293}{294}

Finally, instead of going through all $2^{n - n_1}$ assignments for $\hat{y}$, as in \cref{alg:solve}, the SageMath version stores solutions in \texttt{defaultdict}s. This way, the procedure may only iterate through stored $\hat{\mathbf{y}}$ values, i.e. those where $U_0(\hat{\mathbf{y}}) = 0$:
\pylisting[label={lst:sage:history}]{src/sage/dinur.sage}{342}{351}
The \texttt{c\_debugging} part should be ignored here. The other parts should then show a strong resemblance to \cref{alg:solve}.

\paragraph{Outputting isolated solutions in reality.} The function \texttt{output\_potentials()} is the SageMath equivalent of \cref{alg:output}. To compute isolated solutions using the $U$ polynomials, the SageMath implementation takes two approaches, as noted earlier. The \texttt{fes\_recovery} parameter chooses either a FES-based interpolation and evaluation or Dinur's proposed method of using the boolean Möbius transform and using \texttt{compute\_u\_values()}. With Dinur's proposed method of computing isolated solutions, the code first obtains \texttt{V} and \texttt{ZV}, being a \texttt{defaultdict} and a list of \texttt{defaultdict}. Once those have been saved, the procedure goes on to interpolate the $U$ polynomials and store them in an array, \texttt{U}:
\pylisting{src/sage/dinur.sage}{216}{218}
using the appropriate parameters ($w$ for $U_0$ and $w + 1$ for the other $U_i$s). Here, the procedure also includes \texttt{sub\_ring} which is a polynomial ring with indeterminates $x_0$ through $x_{n - n_1 - 1}$ instead of $x_0$ through $x_{n - 1}$, as the $U$ polynomials are defined over the $\mathbf{y}$ variables (the first $n - n_1$ variables). Using this approach helped simplify the prototype implementation, as the Möbius transform then could be implemented by the recursive formula (see \cref{sec:prereq:poly_interp}). This does of course add the overhead of addition and multiplication using SageMath polynomial classes while potentially also using large amounts of stack-based memory. However, as the SageMath code acts as a prototyping platform, this is not necessary to change.

Although the traditional Möbius transform takes in either an array representing a polynomial to be evaluated or the full set of evaluations in order to interpolate a polynomial, the code called in the snippet above works as originally intended by Dinur. The transform takes in sparse sets of evaluations in order to interpolate the $U_0$ and $U_i$ polynomials, with the weight values defining the recursion depth for the Möbius transform.

Note, the way that the procedure is implemented using the Möbius transform for interpolation and evaluation is not the most efficient, however, it does resemble the pseudo-code to quite a large degree. Should one be interested in implementing the Möbius transform in Python or SageMath and running the code with that instead, the code may be extended via the \texttt{src/sage/mob\_new.sage} file. Also, the symbolic method of creating an array representing the polynomial, then evaluating and then converting the output to an array of evaluations (seen in the snippet below)
\pylisting[label={lst:sage:output_mob}]{src/sage/dinur.sage}{228}{251}
should also see a revision if the Möbius transform is more ''properly'' implemented in \texttt{src/sage/mob\_new.sage}. Pseudo-code and explanation of the Möbius transform can be found in \cref{sec:prereq:poly_interp}.

The remainder of the implementation ensures to convert the evaluations of the $U_i$ polynomials into the actual $z_{i - 1}$ bit of an isolated solution, depending on the evaluation of $U_0$. The code can be seen below.
\pylisting{src/sage/dinur.sage}{259}{264}
The output dictionary \texttt{out} is stored as a \texttt{defaultdict} basically due to memory concerns. This of course adds processing, but it should be clear by now that execution speed was not always a priority in the SageMath code.

If the caller alternatively sets the \texttt{fes\_recovery} parameter to \texttt{True}, the algorithm uses the FES-based interpolation and evaluation, described in \cref{sec:ext:fes_interp}. The gist of the code when going with a FES-based interpolation is the following (ignoring the timing code, of course):
\pylisting{src/sage/dinur.sage}{193}{205}
The most notable difference between the two approaches is the combination of interpolation and evaluation into one. Since both the $U_0$ and the $U_i$ polynomials are interpolated in the same procedure, the \textit{weight} or \texttt{w} parameter is set to \texttt{w + 1} to accommodate for interpolation of both the $U_i$s and $U_0$. The hybrid approach is described generally in \cref{sec:ext:fes_interp:interp_recover}.

\paragraph{Computing $U$-polynomial interpolation points.} Computing the interpolation points, used for the $U$-polynomials takes place in much the same way as Dinur described it in \cite{eurocrypt-2021-30841}. The procedure \texttt{compute\_u\_values()} in \texttt{src/sage/dinur.sage} handles this, and is more or less the same setup as \cref{alg:uvalue}. One difference that affects performance is the use of dictionaries (\texttt{defaultdict} specifically), instead of lists, as the storage solution for the interpolation points.
\pylisting{src/sage/dinur.sage}{158}{159} 
As already discussed, regarding \texttt{output\_solutions()}, this choice was merely made due to memory concerns as the \texttt{defaultdict} serves as a way of doing lookups on non-existing keys without taking up too much valuable memory.

\subsubsection{FES procedures} \label{sec:impl:fes}

\paragraph{Bruteforce and FES as we know it:} One aspect of the \texttt{compute\_u\_values()} process that is different from \cite{eurocrypt-2021-30841} is the \texttt{bruteforce()} procedure. The description in \cite{eurocrypt-2021-30841} leaves much to the imagination as it is only really stated that the FES procedure of \cite{cryptoeprint:2013/436} and \cite{ches-2010-23990} would be used to evaluate the sparse set of inputs, $W^{n - n_1}_{w + 1} \times \{0,1\}^{n_1}$. However, Dinur does make arguments for two general approaches and their performance penalties/impacts. These alternatives are described as either simply iterating through the set $W^{n - n_1}_{w + 1}$ while going through all $\{0,1\}^{n_1}$ values at each such iteration, or the use of \textit{monotonic Gray codes}. The structure of monotonic Gray codes was briefly mentioned in \cref{sec:prereq:fes:gray_codes}. Due to simplicity and the negligible performance penalty, the choice here was to use the former approach. 

The \texttt{bruteforce()} procedure can be found in \texttt{src/sage/fes.sage} and is in essence rather simple. The function simply slices the polynomial system into $1 + n + \binom{n}{2}$ integers and uses the bit-sliced representation to run the FES procedure on the entire system at once. The procedure loops through a sequence of integers $i = 0, \dots 2^{n - n_1} - 1$ skipping any value of $i$ where the $hw(i) > d$ for a parameter $d = w + 1$. For each value of $i$ where $hw(i) \leq w + 1$, a \textit{prefix} is computed and stored as a list of indices for the $1$ bits in $i$.
\pylisting{src/sage/fes.sage}{173}{173}
This prefix represents the value of $i$, by storing the indices of the 1-bits, and is used for representing the FES procedure \textit{state}.

The FES procedure was not originally intended to evaluate across a sparse set of inputs and so some modifications had to be made. First off, the FES code relies on a data class \texttt{State}:
\pylisting[label={lst:sage:state}]{src/sage/fes.sage}{8}{14}
In many areas, this state representation is similar to that of \cref{alg:fes_eval}, however, it has an added \texttt{prefix} attribute. This attribute helps the state class maintain information between different calls to the \texttt{fes\_eval()} procedure. The state, \texttt{s}, is updated whenever a new value of $i \in W^{n - n_1}_{n_1}$ is reached in the counter using the \texttt{update()} procedure:
\pylisting{src/sage/fes.sage}{174}{174}
This process is simply partially evaluating the polynomials of $\Tilde{\mathcal{P}}_k$ on the counter value $i$, in the first $n - n_1$ variables. When a new counter value, $i' \in W^{n - n_1}_{w + 1}$, is reached the \texttt{update()} function ensures to \textit{turn on} or \textit{turn off} (set variables to 1 or 0, respectively) the bits in the derivatives \texttt{s.d1} and \texttt{s.d2}, as well as the evaluation \texttt{s.y}. This process depends on which variables were changed to 1 and which were changed to 0 going from counter value $i$ to $i'$. An example of this process is the following code:
\pylisting{src/sage/fes.sage}{77}{81}
This snippet goes through all variables that are turned off, going from $i$ to $i'$, and subtracts the coefficient of the monomial $x_{idx}x_{k + n - n_1}$ from the value of $\frac{\partial f}{\partial x_{k + n - n_1}}$. Likewise, the "evaluation", or \texttt{s.y}, also takes effect from changing the assignments of the first $n - n_1$ variables. For this reason, the procedure must ensure to subtract the coefficient of the monomial $x_{idx}$ from the evaluation \texttt{s.y}. By Adding and subtracting these coefficients, the procedure computes a partial evaluation and its effect on the derivatives as well. The benefit of doing this is that the FES initialization phase only has to run \textit{once}, as the state may simply just be updated when reaching counter value $i'$.

Similarly, the \texttt{update()} function handles the other effects of changing assignments of the first $n - n_1$ variables. Variables are also handled similarly to the process just described when turned \textit{on} between two calls to \texttt{update()}. In general, the procedure turns \textit{on} or \textit{off} variables in the derivative tables and evaluation \texttt{s.y} based on which monomials are affected by said variable assignment change. By then storing the \texttt{prefix} inside the state, the procedure can subsequently handle new changes without having to entirely reboot the FES procedure.

The subsequent code in \texttt{bruteforce()} may then simply call the \texttt{fes\_eval()} procedure with the newly update state \texttt{s} as such:
\pylisting{src/sage/fes.sage}{175}{175}
which internally works much like the pseudo-code described in \cref{sec:prereq:fes}. The function \texttt{fes\_eval()} handles two cases, depending on whether or not it is called by \texttt{bruteforce()} or \texttt{fes\_recover()}. For now, this section will focus on the code of \texttt{bruteforce()} and related parts. The function declaration looks like
\pylisting{src/sage/fes.sage}{118}{118}
where the \texttt{compute\_parity} parameter is set to false when called from \texttt{bruteforce()}, as this then ensures that the procedure returns solutions, like traditionally done in FES. The parameters of \texttt{f}, \texttt{n} and \texttt{n1}, should be clear from \cref{sec:prereq} and \cref{sec:dinur}, or \cite{eurocrypt-2021-30841} and \cite{cryptoeprint:2013/436}. The parameters of \texttt{prefix} and \texttt{s} relate to the state processing described just now.

Whenever the \texttt{fes\_eval()} function is called with \texttt{s = None}, the code has to initiate a new state \texttt{s}. In the same vein as the \texttt{update()} function, the \texttt{init()} function (in \texttt{src/sage/fes.sage}) ensures to initiate the first and second derivatives according to the prefix that the system is being partially evaluated on. This leads to computations like
\pylisting{src/sage/fes.sage}{57}{61}
where the computation is very much like the one in \texttt{update()}. Of course, other than initializing the state according to the current prefix the state also needs to be initialized in accordance to \cref{alg:fes_init}.

Once the state has been initialized, the execution of \texttt{fes\_eval()} follows the ideas of \cref{alg:fes_eval} closely. However, the procedure essentially runs an exhaustive search on the space $\{0,1\}^{n_1}$, but solutions from $W^{n - n_1}_{w + 1} \times \{0, 1\}^{n_1}$ are needed. Therefore, instead of storing the value of $s.i \oplus (s.i \rightshift 1)$ (the Gray code value of \texttt{s.i}), the binary representation of the prefix has to be prepended to the Gray code counter. 

Once all solutions have been found and stored with the currently set \textit{prefix}, the procedure may not yet return control to \texttt{bruteforce()}. Since the \texttt{state} is re-used and updated between successive calls to \texttt{fes\_eval()}, the state also has to reset certain values. That is, at the end of \texttt{fes\_eval()} the procedure resets \texttt{s.d1}, \texttt{s.d2} and \texttt{s.i} to their initial values from when \texttt{fes\_eval()} was initially called. The snippet here shows this process:
\pylisting{src/sage/fes.sage}{153}{155}
where the code "subtracts" second derivatives added to the first derivative (during the search for solutions) for each of the first $n_1-1$ \textit{unassigned} (not partially evaluated) variables. Following this, the procedure can reset \texttt{s.y}. Inspecting the xor operations of \cref{alg:fes_step}, it should be clear how this process resets \texttt{s.d1} and \texttt{s.y}. Of course, the counter in \texttt{s.i} is also reset to ensure that the next run of \texttt{fes\_eval()} only goes through $\{0,1\}^{n_1}$ as well. 

The last part of the \texttt{bruteforce()} procedure in \texttt{src/sage/fes.sage} adds the solutions obtained by \texttt{fes\_eval()} as lists of $GF(2)$ elements. Once all prefixes, or all values of $W^{n - n_1}_{w + 1}$, have been processed the algorithm returns all solutions found.

\paragraph{FES-based recovery:} The procedures STEP, $\text{BIT}_1$, and $\text{BIT}_2$ from \cref{alg:fes_step} are all implemented in a quite straightforward manner, meaning that they will not be explained here. In return, the \texttt{fes\_recover()} function from \texttt{src/sage/fes\_rec.sage} probably deserves some explanation. There are essentially three parts to this function; \texttt{fes\_recover()} itself, \texttt{fes\_eval()} with \texttt{compute\_parities} set to \texttt{True}, and \texttt{part\_eval()}. As the observant reader may have already noticed, the \texttt{fes\_recover()} function is an implementation of the procedure described in \cref{sec:ext:fes_interp} or \cref{alg:fes_recover}.

As is described in \cref{sec:ext}, the FES-based recovery (\cref{alg:fes_recover}) acts as an alternative to interpolation and evaluation using the Möbius transform. In the case of Dinur's solver, this means that it needs to fill the entries of a $(n_1 + 1) \times 2^{n - n_1}$-sized array, containing evaluations of the $U$ polynomials. In the SageMath code, these entries are bit-sliced such that the evaluations of the $n_1 + 1$ $U$ polynomials fit into a single integer in a $2^{n - n_1}$-sized array.

For the FES-based recovery to work, the procedure requires the set $W^{n - n_1}_{w + 1} \times \{0,1\}^{n_1}$ as interpolation points, just like the Möbius transform. Internally, the \texttt{fes\_recover()} procedure computes these points, instead of having to pre-compute them and pass them as input to the procedure. For this reason, the \texttt{state} class (\cref{lst:sage:state}) is used once more. The \texttt{fes\_recover()} procedure internally partially evaluates the system $\Tilde{\mathcal{P}}_k$, like in \texttt{bruteforce()}, before computing the interpolation points. Now, \texttt{fes\_recover()} also calls \texttt{fes\_eval()} to compute these interpolation points, however, the \texttt{compute\_parities} parameter is set to \texttt{True} this time. Passing this parameter changes the behavior of \texttt{fes\_eval()} from computing solutions of a partially evaluated system, to directly computing the summations from \cref{alg:uvalue} (like \cref{alg:uvalues:sum}). The value returned from \texttt{fes\_eval()} is now instead the evaluation of $U(\mathbf{y}_{prefix})$, with $\mathbf{y}_{prefix}$ being the vector representation of \texttt{prefix}.

Now, since the FES-based recovery needs to interpolate and evaluate polynomials of variable degree (i.e. the $U$ polynomials), the procedure must implement less specialized code than the likes of \cref{alg:fes_eval}, or \texttt{fes\_eval()} in \texttt{src/sage/fes.sage}. In the SageMath code, this is handled by the derivative \textit{table} (dictionary) \texttt{d} and the array of bit-positions \texttt{k}. Essentially this means that \texttt{fes\_recover()} internally uses two different kinds of FES; a specialized version for quadratic polynomials (computing solutions of $\Tilde{\mathcal{P}}_k$), and the generalized version for interpolation and evaluation.

Fundamentally, the way the table \texttt{d} stores derivative values of varying order is by simply interpreting the counter \texttt{si} as a bitstring, and then selecting maximally the \texttt{degree} first 1-bits of this bit-string. An example of this is $si = 101101_2$ and $degree = 3$, where the index would be $si = 1101_2 = 13$. This is computed using the \texttt{bits()} function, returning an array of indices for all 1-bits in the counter \texttt{si}:
\pylisting{src/sage/fes_rec.sage}{76}{76}
The variable \texttt{k} is here simply an array of these indices. This is very much just the generalized version of $\text{BIT}_1$ and $\text{BIT}_2$ in \cref{alg:fes_step}, or simply $K$ and $\text{BITS}()$ in \cref{alg:fes_recover}. The values in this array \texttt{k} are then used to compute the indices into the derivative table, according to which monomial \texttt{si} represents. An example of the computation of indices into \texttt{d} is:
\pylisting[label={lst:sage:index}]{src/sage/fes_rec.sage}{80}{80}
It should further be noted that index $0$ in \texttt{d} represents the evaluation of \texttt{si} on the $U$ polynomials, just like in \cref{alg:fes_recover}. Also, the derivative table \texttt{d} is bit-sliced, such that each entry contains the corresponding values for each $U$ polynomial.

Then, as the procedure seeks to evaluate the $U$ polynomials on $\{0,1\}^{n - n_1}$, it goes through all values $i = 0, \dots 2^{n - n_1} - 1$. At each iteration, the procedure chooses to interpolate or evaluate given the current iteration count \texttt{si}. In much the same sense as interpolation using the Möbius transform on sparse inputs, the interpolation of \texttt{fes\_recover} occurs whenever the counter value has $hw(i) < d$ where $d$ is the \textit{degree} specified through the \texttt{degree} parameter to \texttt{fes\_recover}. In all other cases, the procedure conversely evaluates the polynomial, given the interpolations computed.

Focusing on the interpolation part for a bit, it can be seen that the line
\pylisting{src/sage/fes_rec.sage}{91}{91}
is rather important. The prefix, much like in \texttt{bruteforce()}, represents the input to the various $U$ polynomials (as discussed alreay); $U(\mathbf{y}_{prefix})$. Internally, the \texttt{part\_eval()} function updates the state \texttt{s} and computes \textit{parities} through \texttt{fes\_eval()}. These parities are then simply returned alongside the updated state \texttt{s}.

Now, the \textit{parities} are nothing more than the values computed in \texttt{compute\_u\_values()}. An example of the parity computation in \texttt{fes\_eval()} is 
\pylisting{src/sage/fes.sage}{144}{148}
Again, this is bit-sliced and so each integer contains $n_1 + 1$ bits, corresponding to each of the $U$ polynomials. Comparing the snippet above to the main loop of \texttt{compute\_u\_values()} (or \cref{alg:uvalue}) it should be clear that these are more-or-less the same computations. Setting \texttt{compute\_parities} in \texttt{fes\_eval()} to \texttt{True} does not affect anything else than how solutions are handled. The procedure still resets the \texttt{state} attributes and still computes evaluations the same as when set to \texttt{False}.

Once the \textit{parities} of a certain prefix have been computed, they may be stored in the derivative table immediately as these represent an evaluation of the $U$ polynomials. Once these have been stored, the procedure can do the \textit{backtracking} described in \cref{sec:ext:fes_interp}. This process is implemented in the following way:
\pylisting[label={lst:sage:ifes_interp}]{src/sage/fes_rec.sage}{97}{109}
To add some explanation, the procedure computes the high-order derivatives using the values of low-order derivatives (and the evaluation) in the for-loop. Of course, the \texttt{prev} variable corresponds to $Q$ in \cref{alg:fes_recover}.

Conversely, if the hamming weight of the counter is sufficiently high, $hw(si) > degree$, the procedure may \textit{evaluate} instead of interpolating. This process does not need the parity computation, as the low hamming weight entries in the derivative table have already been updated by earlier interpolation steps, as explained in \cref{sec:ext:fes_interp}. Therefore, the code is simply going bottom-up computing the high-order derivatives first, like \cref{alg:generalized_fes:step:compute} (in \cref{alg:generalized_fes}). For these computations, the \texttt{degree} first 1-bits of $si$ are once more used in order to compute the derivative table entries required. The following snippet shows these computations:
\pylisting{src/sage/fes_rec.sage}{78}{80}

Once the current iteration either finished interpolation or evaluation, the procedure stores \texttt{d[0]} in the array of evaluations:
\pylisting[label={lst:sage:fes_rec_res}]{src/sage/fes_rec.sage}{113}{113}
Given that this approach is a variant of FES, the evaluation in \texttt{d[0]} is the result of evaluating the $U$ polynomials on the Gray code value of \texttt{si}, and must therefore be stored accordingly in the \texttt{res} array.

As mentioned in \cref{alg:fes_recover}, combining interpolation and evaluation into one procedure allows for a single pass-through of the $2^{n - n_1}$ evaluations needed for the $U$ polynomials. This way, the procedure does not need to store both exponentially-sized arrays for representing the $U$ polynomials plus the $Evals$ array of \cref{alg:output}. However, the derivative table is still quite large, and the computational needs for interpolation and evaluation are still expensive. For an evaluation of using FES-based recovery, see \cref{sec:eval}.

\subsubsection{Möbius Transform and utilities}
\paragraph{Brief note on the Möbius transform.} As mentioned earlier, the Möbius transform implementation(s) can be found in \texttt{src/sage/mob\_new.sage}. The procedure \texttt{mob\_transform()} represents the Möbius transform, however, instead of using lists as described in \cref{sec:prereq:poly_interp} the representation uses the built-in SageMath representation of boolean polynomials. This oddity is the reason that \cref{lst:sage:output_mob} is as comprehensive. Implementing the Möbius transform as described in \cref{sec:prereq:poly_interp}, alongside the \textit{sparse} Möbius transform, will make much of the code in \cref{lst:sage:output_mob} redundant and more readable. By using the boolean polynomial classes of SageMath, computing the Möbius transform is done through the recursive formula specified in \cref{sec:prereq:poly_interp}. Implementing the sparse interpolation can be done by filtering out high-degree monomials after fully interpolating the polynomial from its sparse set of solutions when the transform is computed in this ''symbolic'' way. For inspiration on implementing the Möbius transform less symbolically, implementations like that of \cite{cryptoeprint:2022/1412} are worth a look.

\paragraph{Utilities.} The SageMath codebase in \texttt{src/sage/} provide quite a few extra utility functions, depending on the goal. The \texttt{src/sage/utils.sage} file provides procedures for reading and writing Fukuoka MQ-challenge style files\footnote{\url{https://www.mqchallenge.org/}}, bit-slicing multilinear quadratic polynomials, generating polynomial systems, fetching C functions from the shared library, and more. These utilities are used throughout the SageMath codebase and also in the \texttt{run.py} script, in order to handle smaller tasks that would not require a dedicated SageMath file. Should one seek to extend parts of the SageMath code, or the \texttt{run.py} script, this file should be kept in mind.

\subsection{Core algorithms in C} \label{sec:impl:c}

In many areas, the standard C implementation takes a similar approach to program design as the SageMath counterpart (see \cref{sec:impl:sage}). However, unlike the intent with the SageMath prototype, the purpose of the C code was to test test the algorithm and see what kinds of optimizations are beneficial for it. This subsection seeks to describe the general idea behind the C implementation, drawing parallels to the similar parts in the SageMath code and describing the difference alongside their design choices. Evaluating the usefulness of these optimizations is postponed to \cref{sec:eval}. This subsection focuses on the \textit{shared library} compile-target (see \cref{sec:impl:compile}) as well as the \textit{standardized} implementation, plus any utilities that overlap between codebases.

\subsubsection{Solve, and other top-level procedures} \label{sec:impl:c:solve}
The main entry point into the library is the \texttt{solve()} procedure, residing in \texttt{src/c/standard/mq.c}. This procedure for the most part acts like its SageMath counterpart. However, the \texttt{solve()} procedure expects a bit-sliced system of polynomials in its \texttt{poly\_t *system} parameter. Further, the procedure expects that the monomial ordering is graded lexicographic ordering and that the polynomials in the system have been \textit{linearized}, i.e. the system consists solely of multilinear polynomials. Examining the function declaration, the other parameters should be somewhat self-explanatory:
\clisting{inc/mq.h}{40}{40}
The latter parameter, \texttt{sol}, is an out-parameter containing the solution found, if any.

Now, due to the unrestricted nature of C, the initial part of the procedure allocates memory for the elements like the sub-system $\Tilde{\mathcal{P}_k}$, the matrix $A^{(k)}$ and the solution history:
\clisting{src/c/standard/mq.c}{81}{86}
$\Tilde{\mathcal{P}_k}$ and $A^{(k)}$ are stored in the \texttt{rand\_mat} and \texttt{rand\_sys} variables simply as integer arrays, and reused in each round. The solution history is saved as an array of pointers, called \texttt{potential\_solutions} and its size is defined by the \texttt{MAX\_HISTORY} macro. This macro defines an upper limit on how many rounds the solver may use to search for a solution and can be modified in \texttt{inc/mq\_config.h}. The types of these three variables are not exactly default types in C.

One prominent type in both the vectorized and standard implementation is the \texttt{poly\_t} type. This type is simply a type definition reusing different integer types in C:
\clisting{inc/mq_config.h}{90}{90}
The \texttt{POLY\_TYPE} macro is defined as a uint\{8, 16, 32, 64\}\_t for the \textit{standard} implementation, depending on the compile-flags (see \cref{sec:impl:compile}). The definitions of both the \texttt{POLY\_TYPE} macro and \texttt{poly\_t} reside in \texttt{inc/mq\_config.h}. The other important type is the \texttt{SolutionsStruct}. This struct will be discussed later.

Once sufficient memory has been allocated and relevant parameters computed (such as $n_1$ and $\ell$) the main loop of the algorithm starts. In the SageMath version, the matrix generation and subsequent generation of the subsystem $\Tilde{\mathcal{P}_k}$ could be handled by the polynomial and matrix representation built into SageMath. In the C code, these procedures have to be handled manually. 

Generating the $A^{(k)}$ matrices of \cref{alg:solve} is done through a call to \texttt{gen\_matrix()} in \texttt{src/c/utils.c}. The procedure takes as argument an array of \texttt{poly\_t} to fill and the number of rows, \texttt{n\_rows}, and columns, \texttt{n\_columns}, for the matrix. Since the matrix is supposed to consist of elements from $\eff_2$, each row is an integer sampled in the \texttt{gen\_row()} procedure, thereby representing the row as an integer. These integers are masked so that only the bottom \texttt{n\_cloumns} bits are left. The \texttt{gen\_matrix()} procedure then simply generates the full $\ell \times m$ matrix and computes the rank, by computing the row echelon form of the matrix and counting independent rows in the meantime. The procedure generates matrices using a Las Vegas (algorithmic) approach, by continuously generating matrices until one of rank $\ell$ is obtained.

Given the matrix generated consists of $m$ bits inside a \texttt{poly\_t}, the procedure for generating $\Tilde{\mathcal{P}_k}$ is quite straightforward. Recall that the new system is generated by
\begin{equation} \label{eq:tilde_p_k}
    \Tilde{\mathcal{P}_k} = \left\{\sum_{j = 0}^{m - 1} A^{(k)}_{i,j} \cdot p_j(\mathbf{x})\right\}_{i=0}^{\ell - 1}
\end{equation}
The \texttt{compute\_p\_k()} procedure generates the new system polynomial-by-polynomial, term-by-term. Now, this procedure generates a system of multilinear polynomials, keeping it consistent with the rest of the codebase. As the polynomials are saved bit-sliced, the summation and multiplication in \cref{eq:tilde_p_k} is merely a matter of:
\clisting{src/c/standard/mq.c}{35}{35}
Here, \texttt{GF2\_ADD} is a macro for bitwise \textit{xor} and \texttt{GF2\_MUL} is a macro for bitwise \textit{and}, these and other macros are described in \cref{sec:impl:c_abstr}. The variable \texttt{s} above is equivalent to the $i$ in \cref{eq:tilde_p_k}. The snippet above is the computation for the constant terms of $\Tilde{\mathcal{P}_k}$, however, by sufficient indexing into \texttt{old\_sys} and \texttt{new\_sys} the same approach may be taken to compute other coefficients as well. At last, the procedure also computes the degrees of these polynomials meanwhile.

Once a new system of polynomials has been computed, the procedure goes on to compute the potential solutions for the current iteration. This is where one of the larger deviations from the SageMath code and \cref{alg:solve} takes place. First, the C solver solely makes use of FES-based recovery (see \cref{sec:ext:fes_interp}), with no alternative Möbius transform implementation. Second, the \texttt{solve()} procedure calls the \texttt{fes\_recover()} procedure directly:
\clisting{src/c/standard/mq.c}{119}{119}

Since the procedure of \cref{alg:output} primarily combines interpolation, evaluation, and ''translating'' the recovered evaluations into potential solutions, no real benefit exists that required it to be implemented when the \texttt{fes\_recover()} procedure is used. With the structure of \texttt{fes\_recover()}, the evaluations can be translated and stored directly in the array of solutions \textit{as} they are computed, instead of going through $2^{n - n_1}$ iterations (in \texttt{fes\_recover()}) to compute all evaluations, and then subsequently iterate through all $2^{n - n_1}$ evaluations once more in order to translate them into potential solutions (\cref{alg:output:recover} in \cref{alg:output}). If a Möbius transform procedure would have been implemented, the necessity for an implementation of \cref{alg:output} would be larger. The actual implementation of \texttt{fes\_recover()} is discussed in \cref{sec:impl:c:fes} and \cref{sec:impl:opt}.

Since the FES-based recovery of \cref{sec:ext:fes_interp} is equivalent to the Möbius transforms (interpolation \textit{and} evaluation) of \cref{alg:output}, breaking the theory is not a risk. Now, the reasoning behind not including a Möbius transform implementation was the \textit{implementability}, so to say. The \texttt{fes\_recover()} version was the more desirable choice, both in order to introduce a use-case for this new procedure and also due to its seemingly simple nature. FES implementation also seems to have been tested more in scientific literature, with examples in \cite{cryptoeprint:2013/436}, \cite{cryptoeprint:2022/1412}, and \cite{ches-2010-23990}. This, however, does not mean the Möbius transform cannot be implemented nor that \texttt{fes\_recover()} should be the sole choice for any other implementations of Dinur's polynomial method solver.

The potential solutions computed in \texttt{fes\_recover()} are stored inside a \texttt{poly\_t}. In this representation, the $\mathbf{y}$- and $\mathbf{z}$-bits of the potential solution are stored in the first $n - n_1$ and latter $n_1$ bits, respectively. Further, the $\mathbf{y}$-bits are \textit{not} stored as their Gray code value.

With the \textit{solution checking} phase of the C implementation, the code once again diverges from the SageMath and reference material (\cref{alg:solve}). Instead of storing the solutions in a dictionary or full $2^{n - n_1} \times (n_1 + 1)$ size array, only potential solutions with $U_0(\hat{\mathbf{y}}) = 1$ are stored. These are stored sequentially in an array. The storage of these lists of potential solutions is done through the struct:
\clisting{src/c/standard/mq.c}{19}{23}
Since the code cannot simply make a lookup into a dictionary or array using the $\mathbf{y}$-bits as key or index, the history checking phase differs quite a bit from \cref{alg:solve} and \cref{lst:sage:history}. 

Due to the way that \texttt{fes\_recover()} is implemented, the potential solutions are stored with their $\mathbf{y}$-bits (recall, not Gray code) in increasing order (interpreting these bits as unsigned integers). Since the conversion to and from Gray code ordering acts like a bijective mapping, two $\mathbf{y}$ values that are equal correspondingly mean that their Gray code values are equal. This way, searching for some Gray code value in an array ordered this way may be performed by linearly comparing (non-Gray code) $\mathbf{y}$-bits. Once some $\mathbf{y}$-bits of a larger \textit{magnitude} have been found, the procedure is guaranteed that the Gray code value initially searched for is not present.

Using the sorting just discussed, the procedure may simply loop through all previous lists of potential solutions, using the sorting of the $\mathbf{y}$-bits as an indicator of whether or not a solution could still be found. That is, the procedure checks all the previous lists of potential solutions (\texttt{k1}):
\clisting{src/c/standard/mq.c}{157}{157}
Here, each iteration then goes through the \texttt{poly\_t}s stored in the history, or the \texttt{k1}th old list of potential solutions:
\clisting{src/c/standard/mq.c}{159}{160}
until it encounters a historic solution with a larger non-Gray code $\mathbf{y}$ value; 
\clisting{src/c/standard/mq.c}{165}{168}
or one where the historic solution and the newly found solution are identical;
\clisting{src/c/standard/mq.c}{169}{170}
This ensures that the procedure checks only the strictly necessary historic solutions, linearly. The linear search could also be replaced with a binary search-like strategy. Alternatively, a dictionary could of course be implemented, however, it is unclear whether or not this would prove a dramatic benefit. Another alternative would be to allocate all $2^{n - n_1} \times (n_1 + 1)$ entries in a table as originally proposed in \cite{eurocrypt-2021-30841}. Of course, choosing to allocate room for all evaluations of the $U$ polynomials will drastically limit the problem sizes that the algorithm may handle in practice (on machines without unlimited memory).

Finally, should the procedure encounter identical potential solutions, the code acts more or less as expected:
\clisting[label={lst:c:history_check}]{src/c/standard/mq.c}{171}{196}
In this snippet, the code ensures to convert the $\mathbf{y}$-bits into its Gray code counterpart, before combining the $\mathbf{y}$- and $\mathbf{z}$-bits into one integer (or \textit{potential solution}). The potential solution is then evaluated on the system to check if it is an actual solution to the system $\mathcal{P}$. If so, the procedure cleans up and returns with the solution stored in the out-parameter \texttt{poly\_t *sol}.

If no solution was found, or an error occurred along the way, the procedure returns $1$. Therefore, if a $1$ is returned from a call to \texttt{solve()} the value in the \texttt{sol} pointer represents an invalid solution. Returning a zero conversely means success and that \texttt{sol} contains a valid solution.

\subsubsection{FES} \label{sec:impl:c:fes}
\paragraph{FES-recovery in C.} Examining the \texttt{src/c/standard/fes.c} file many of the procedures have a corresponding implementation in the SageMath code. Procedures like \texttt{init()}, \texttt{update()}, \texttt{step()}, and the various bit-indexing functions are implemented by the same principles in both the C codebases and the SageMath codebase. Therefore, procedures like these will not be discussed greatly in this section.

Since the implementations of \cref{alg:solve} in C both solely make use of the \texttt{fes\_recover()} approach from \cref{sec:ext}, this section will mainly describe the approach taken for the non-vectorized version of \texttt{fes\_recover()}. Finally, at the end of the section a simple FES implementation for quadratic systems, as described in \cref{sec:prereq:fes}, will be described.

All FES-related procedures and declarations can be found in \texttt{inc/fes.h} and \texttt{src/c/standard/fes.c} (or \texttt{src/c/vectorized/fes.c}, for the vectorized version). Examining the declarations in the header file for non-vectorized compilation targets, one of the more important declarations is
\clisting[label={lst:c:state}]{inc/fes.h}{52}{59} % C State
being the state used by FES to store relevant values like derivatives and prefixes. Similarities to \cref{lst:sage:state} should be obvious. The \texttt{uint8\_t *prefix} acts as an array in much the same way as the \texttt{prefix} attribute in \cref{lst:sage:state}, although integers are limited to a single byte. This is more than sufficient, given that the solver could not feasibly solve systems with more than $256$ variables, and so the positions saved in \texttt{uint8\_t *prefix} would never reach such amounts.

Another important declaration is that of \texttt{fes\_recover()}. A look into the file would also show declarations for \texttt{fes()} and \texttt{bruteforce()}, however, as mentioned these procedures are explained near the end of this subsection. The \texttt{fes\_recover()} declaration is quite similar to that of its SageMath counterpart
\clisting{inc/fes.h}{106}{108} % C fes_recover declaration
The use of the \texttt{poly\_t *} for storing solutions was already described and replaces the need for \texttt{res} array used in the SageMath implementation of \texttt{fes\_recover()} (\cref{lst:sage:fes_rec_res}). The return value is made to be an error code, whereas \texttt{poly\_t *results} and \texttt{size\_t *res\_size} are out-parameters for the potential solutions found and the amount of these, respectively.

Inside \texttt{src/c/standard/fes.c}, the two top-most functions are \texttt{init\_state()} and \texttt{destroy\_state()}. These act like a constructor and a destructor, respectively, for the \texttt{state} struct shown in \cref{lst:c:state}. The constructor allocates heap memory according to the parameters of the problem instance, like $n$ and $n_1$. Consequently, the memory has to be freed to avoid memory leaks, which is handled in \texttt{destroy\_state()}. For anyone seeking to expand the codebase, the \texttt{init\_state()} procedure will not take ownership over any passed pointers but will instead copy their data.

Next, in the same file, the \texttt{fes\_recover()} definition is found. Although the similarities between the C implementation and \cref{alg:fes_recover} (or the SageMath version in \texttt{src/sage/fes\_rec.sage}) are noticeable, some areas still deserve an explanation. At the beginning of the procedure, the code initializes the different tables and structures needed
\clisting{src/c/standard/fes.c}{458}{474}
The most interesting would be the derivative table \texttt{poyl\_t *d} allocated at \srcref{src:c:d_alloc}. For the same reason as not storing potential solutions in a dictionary, the derivatives are not stored in one either. Instead, the table is a dynamically allocated array and the actual size of the array is stored in \texttt{size\_t d\_size}. The size is calculated as 
\begin{equation}
    d_{size} = \sum_{i = 0}^{d} \binom{n - n_1}{i}.
\end{equation}
The indexing itself is computed using the \texttt{monomial\_to\_index()} function (from \texttt{src/c/standard/fes.c}), in order to work with the size of the table \texttt{d}:
\clisting[label={lst:c:index}]{src/c/standard/fes.c}{94}{112}
The reasoning behind this different indexing scheme can be found in \cref{sec:impl:opt:fes_rec}.

Once all tables and values have been set up, the procedure starts computing the \textit{parities}, or evaluations, of the $U$ polynomials. Like in the SageMath code, this is done using a procedure called \texttt{part\_eval()}, handling \texttt{state} updates and calls to \texttt{fes\_eval\_parity()}. Now, notice that \texttt{fes\_eval\_parity()} is a separate procedure from \texttt{fes\_eval\_solutions()}. Instead of combining this alternative FES version, where parities are computed instead of storing solutions, the C code separates them, allowing for better readability and extendability. In the \textit{standard} C codebase, the \texttt{fes\_eval\_solutions()} computes and stores solutions to the input system, while \texttt{fes\_eval\_parities()} computes the parities from \cref{alg:uvalue}.

After parities have been computed and returned to the \texttt{fes\_recover()} procedure, it directly checks the parities for a potential solution and does relevant translations if needed. Recall that the C codebase does not have a procedure like \cref{alg:output}, and therefore instead requires solution checking and \textit{translation} somewhere else, being directly in \texttt{fes\_recover()} in this case. The code for checking solutions is 
\clisting[label={lst:c:solution_check}]{src/c/standard/fes.c}{486}{490}
The above snippet shows how parities are handled for $\hat{\mathbf{y}} = \mathbf{0}$, whereas a similar snippet can be found for $\hat{\mathbf{y}}_i$, for $0 < i < 2^{n - n_1}$. Beware, the macros used in the conditional check are explained in \cref{sec:impl:c_abstr}. The if-statement checks for the case where $U_0$ evaluates to one (recall \cref{sec:dinur:dinur_alg}), as the parities and $\mathbf{y}$-bits then form a potential solution to the system $\mathcal{P}$. If so, the the $\mathbf{y}$-bits are stored as is, and the parities are converted into the corresponding $\mathbf{z}$-bits. Then both sets of bits are combined into a single \texttt{poly\_t}. The case for $\hat{\mathbf{y}}_i$, where $0 < i < 2^{n - n_1}$, replace \texttt{parities} for the \texttt{d[0]} entry in the if-statement and $\mathbf{z}$-bits, as it now interpolates and evaluates using that directly. This of course also stores the counter value \texttt{si}, instead of 0, as the $\mathbf{y}$-bits. 

As already mentioned, much of the procedure works like \cref{alg:fes_recover} and the SageMath counterpart. Therefore, the specifics of interpolation/evaluation are mostly the same. Computing the bit-positions required for interpreting the counter as a monomial (as \cref{alg:fes_recover:bits} in \cref{alg:fes_recover}) is done through the \texttt{bits()} function, located in \texttt{src/c/standard/fes.c}. The positions are stored in an array \texttt{k} like the SageMath counterpart does it 
\clisting{src/c/standard/fes.c}{503}{503}
which may then be used to compute indices using \texttt{monomial\_to\_index()} (\cref{lst:c:index}), as follows
\clisting{src/c/standard/fes.c}{507}{508}

In the interpolation phase, the $\mathbf{y}$-bits are represented by an array of the bit-positions for each 1-bit in the counter-value (limited to the first $n - n_1$ bits). This is used for the \texttt{uint8\_t *prefix} from \cref{lst:c:state}. Computing the prefix, the Gray code value of the counter \texttt{si} is used:
\clisting{src/c/standard/fes.c}{523}{526}

Now, the rest of the interpolation phase is setup much like \cref{lst:sage:ifes_interp}, and will therefore not be explained in-depth. Due to the nuances of C, when compared to SageMath, there are certain less interesting differences. See \cref{sec:impl:fes} for an explanation of the SageMath code, \cref{alg:fes_recover} for the general approach, and \texttt{src/c/standard/fes.c} for the standard C source code.

Should an error occur during execution of \texttt{fes\_recover()}, the procedure cleans up its memory and returns 1, much like the error codes in the \texttt{solve()} procedure. In case no error occurred, the procedure returns 0.

\paragraph{FES for the curious.} A simple implementation of the FES approach (for quadratic polynomials) discussed in \cref{sec:prereq:fes} was also implemented. This exists mostly for comparison against Dinur's solver, however, it may still be used for solving systems. The remaining part of this subsection is dedicated to a brief look into this.

There are two methods for running FES directly in the C code; the \texttt{bruteforce()} procedure and \texttt{fes()} procedure. The \texttt{bruteforce()} procedure is an implementation of the \texttt{BRUTEFORCE()} procedure from \cref{alg:uvalue}. The declaration can be found in \texttt{inc/fes.h} and the implementation in \texttt{src/c/standard/fes.c}. The procedure is declared as 
\clisting{inc/fes.h}{76}{77}
which is rather similar to that of \cref{alg:uvalue}. Here, the \texttt{poly\_t *solutions} parameter is an out-parameter for storing solutions. The return value is the number of solutions stored. This out-parameter of course expects the pointer to point to a \textit{sufficiently}-sized chunk of memory for storing solution in.

If the goal is to run FES more in line with \cite{cryptoeprint:2013/436} or \cite{ches-2010-23990}, the \texttt{fes()} function is defined to be able to handle this:
\clisting{inc/fes.h}{90}{90}
This procedure is not as heavily optimized as the GPU version of \cite{ches-2010-23990}, or the FPGA version of \cite{cryptoeprint:2013/436}, but has received the same level of \textit{care} as the procedure \texttt{fes\_eval\_parity()} used inside \texttt{fes\_recover()}. The solutions found are stored in the parameter \texttt{poly\_t *solutions} and the return value holds the amount found.

\subsubsection{Utilities and benchmarking} \label{sec:impl:c:util_bench}
Besides the C procedure discussed up to this point, a few more can be found in \texttt{src/c/standard/utils.c} and \texttt{src/c/standard/benchmark.c}. The most notable utility procedures are the \texttt{gen\_matrix()} procedure and the \texttt{eval()} procedure. The former was briefly described in \cref{sec:impl:c:solve}, whereas the latter is simply a procedure that evaluates a bit-sliced system on some \textit{full} assignment of variables, in parallel. Declarations for these procedures can be found in \texttt{inc/utils.h}, if needed for extending or reusing the codebase.

When the shared library is compiled, a few benchmarking tools are also available. First off, if the goal is to solely benchmark the solver, the procedure 
\clisting{inc/benchmark.h}{34}{34}
takes as input a list of bit-sliced systems that will then be run through the \texttt{solve()} function. The procedure computes timings for different points of interest in the codebase but also computes the number of potential solutions stored, as well as the balance of interpolation versus evaluation in \texttt{fes\_recover()}. All of the computed values are averaged according to how many calls to \texttt{solve()} that finished successfully, i.e. returned a valid solution. The stored timings and iteration counts can be accessed through the global variables declared in \texttt{inc/benchmark.h}, prefixed with a \texttt{g\_}. 

If a non-vectorized variant of the codebase was compiled, a benchmarking procedure for the \texttt{fes()} procedure is also available. The declaration is as
\clisting{inc/benchmark.h}{38}{38}
This procedure acts much the same way as \texttt{e2e\_benchmark()}, just now solely for FES. Computed timings are stored in separate global variables than those used by \texttt{e2e\_benchmark()}.

Benchmark timings are computed using the \texttt{BEGIN\_BENCH()} and \texttt{END\_BENCH()} mac\-ros, as well as \texttt{READ\_BENCH()}. The names should make the purposes of the macros more understandable. Should there be interest in adding more benchmarks; declaring an extern variable in \texttt{inc/benchmark.h} for storing timings (or another type of benchmark value), initializing it to a suitable value in a user-chosen position, and then adding appropriate macro-calls at the points of interest is sufficient.
\subsection{Optimizations} \label{sec:impl:opt}
Different kinds of optimizations were implemented either directly in the codebase described in \cref{sec:impl:c} or in the alternative codebase in \texttt{src/c/vectorized/}. This subsection seeks to go through the most prominent optimizations and why they are used.

\subsubsection{FES-based recovery} \label{sec:impl:opt:fes_rec}
\paragraph{Internal optimizations to FES-recover.} For the C codebases, the choice of procedures for interpolating and evaluating the $U$ polynomials was \texttt{fes\_recover()}. One benefit of going with \texttt{fes\_recover()} is that interpolation and evaluation of these polynomials can be done in \textit{one} pass-through of their $2^{n - n_1}$ evaluations, instead of two separate calls to the Möbius transform.

Another effect of using the \texttt{fes\_recover()} approach was the ability to more easily store only the potential solutions, instead of allocating memory for all evaluations. Alternatively, as is described in \cref{sec:dinur:dinur_alg}, the procedure would have to store all 
$$
    2^{n - n_1}
$$ 
evaluations. In \cite{eurocrypt-2021-30841} it was shown that the number of suggested solutions in a round was about 
$$
    2^{n - 2n_1},
$$
and so the saved memory could prove a benefit for larger values of $n_1$. Although the current implementation does allocate a large chunk of memory at once, memory is reallocated once the amount of potential solutions is known. Other alternatives for benefitting from compactly storing potential solutions also exist, depending on what the end goal is.

Another memory-saving element used in \texttt{fes\_recover()} is the alternative indexing scheme used in the C code, compared to that of the SageMath code. This alternative indexing was described in \cref{sec:impl:c:fes}. Reusing the SageMath code, the derivative table \texttt{d} would have to be a large exponential in size, as monomial representations would be sparsely scattered depending on their bit-string representation. The approach taken instead yields a memory consumption of 
$$
    \sum_{i = 0 }^{d} \binom{n - n_1}{i} < \left(\frac{(n - n_1)e}{d}\right)^d
$$
where $d$ is the degree passed to \texttt{fes\_recover()} as \texttt{deg}. Now, this is still an exponential function in $n$, as $d$ (or \texttt{deg}) is a function of $n$. However, this exponential function has a much smaller growth in theory. For actual data on the memory usage, see \cref{sec:eval:mem}. Of course, the disadvantage of this approach is the additional computational overhead used to compute the different indices, compared to the more \textit{naive} approach chosen in the SageMath prototype (\cref{sec:impl:fes}).

In total, the memory consumption of \texttt{fes\_recover()} is lowered, and in expectation, it is rather competitive to using in-place Möbius transforms like \cref{alg:mob}. Using the memory-efficient Möbius transform suggested in \cite{eurocrypt-2021-30841}, could pose a strong alternative to this approach.

\paragraph*{Removing \texttt{output\_potentials}} Although the SageMath prototype kept \texttt{output\_potentials()}, the choice was to leave it out in the C code. Due to the choice of using the evaluation and interpolation process of \cref{sec:ext:fes_interp}, integrating solution filtering and translation directly into the procedure was more intuitive.

Since each iteration of the outer-most loop of \cref{alg:fes_recover} (and thereby its implementations), discretely, either evaluate or interpolate, integrating filtering and translation directly into \texttt{fes\_recover()} was quite simple. Other than allowing for tighter packing of potential solutions in the returned array, this process also removes the need for a separate loop that filters and translates by going through all $2^{n - n_1}$ evaluations (\cref{alg:output:recover} in \cref{alg:output}). Therefore, the time taken to go through all solutions once more, in order to \textit{post-process}, is no longer effecting the total solve time. Of course, as already mentioned, this comes at the cost of potentially having a heavier computational load at each iteration of \texttt{fes\_recover()}.

\subsubsection{Vectorization and parallelization} \label{sec:impl:opt:parallel}
Various methods of parallelizing the procedure were used, including the use of SIMD instructions and multicore CPUs. Of course, the shared library is compiled with GCCs \texttt{-O3} flag, which implies quite a few optimizations occur at compile-time. However, some optimizations can be hard to determine statically and so active care was taken to provide further optimizations. 

A smaller method of optimizing storage is the use of the different Make flags available. The Make flags can currently tell the solver what size of integer the input systems (bit-sliced) and their solutions should be stored in. This can help reduce the overall memory footprint. Currently, the SIMD implementation divides $\mathcal{P}$ and $\Tilde{\mathcal{P}_k}$ into separate integer sizes, which is a feature that is not readily available in the non-SIMD version. Using smaller integer sizes for the smaller systems $\Tilde{\mathcal{P}}_k$ allows for storing more polynomial terms in a cacheline, boosting performance to some extent. As these terms are accessed quite frequently, and in an almost sequential manner, this can boost performance on a low level. Therefore, having separate integer sizes for $\mathcal{P}$, $\Tilde{\mathcal{P}}_k$, and possibly also solutions, could prove beneficial for the standard version as well.

Although it is possible to vary integer sizes for both the standard and vectorized implementations, both are limited to input systems of 64 polynomials and 64 variables (maximally). This may be extended, see \cref{sec:impl:c_abstr}.

\paragraph{Bit-slicing.} As bit-slicing is a simple method of obtaining linear speedups, especially when used in the context of systems of boolean polynomials, it was a safe choice in this case. Since Dinur's polynomial-method algorithm can work with multiple polynomials at once in almost every area, many of the procedures and sub-procedures benefit from this.

In both the non-SIMD builds and the vectorized builds, the input system to \texttt{solve()} is bit-sliced (mentioned in \cref{sec:impl:c:solve}). The sub-system $\Tilde{\mathcal{P}}$ is generated in \texttt{compute\_p\_k()} (both the version in \texttt{src/c/standard/mq.c} and \texttt{src/c/vectorized/mq.c}) bit-sliced as well. The multiplication of individual matrix indices, recall \cref{eq:tilde_p_k}, with terms of the polynomials of $\mathcal{P}$ is quite easily implemented with bit-wise operations. Using bit-slicing and bit-wise \texttt{and} is then simply a parallel multiplication. Then the summation is a matter of computing the parity of the integer representing said multiplication. 

Also in \texttt{fes\_recover()}, bit-slicing benefits the internal calls to \texttt{fes\_eval\_parity()} as well, through the evaluations of the $n_1 + 1$ polynomials; $U$. The evaluations of these polynomials, i.e. the parities computed in \texttt{fes\_eval\_parity()} and in the evaluation phase of \cref{alg:fes_recover}, are stored and computed bit-sliced as well. Processing and checking for candidates is then merely a matter of bit-masking. 

Generally, most steps of Dinur's polynomial-method solver benefit from bit-slicing, as many operations can be done independently in parallel. The polynomials and systems are not always the same, as it was just explained that both operations on $\mathcal{P}$ and the $U$ polynomials can benefit from this.

\begin{figure}[t]
    \centering
    \begin{tikzpicture}[
        ->,  % makes the edges directed
        >=stealth', % makes the arrow heads bold
        node distance=3cm, % specifies the minimum distance between two nodes. Change if necessary.
        every state/.style={thick, fill=gray!10}, % sets the properties for each ’state’ node
        initial text=$ $, % sets the text that appears on the start arrow
    ]
        \node [state] (master) {\texttt{run.py}};
        \node [state, below of=master] (p1) {Core 2};
        \node [state, left = 1.5cm of p1] (p0) {Core 1};
        \node [state, right = 3cm of p1] (pn) {Core $2^{n_p}$};
        \node at ($(p1)!.5!(pn)$) {\ldots};

        \draw
            (master) edge[below, anchor=south, sloped] node{$\mathcal{P}^{(0)}$} (p0)
            (p0) edge[bend left, above, anchor=south, sloped] node{$subsol$} (master)
            (master) edge[bend left, below, sloped, anchor=south] node{$\mathcal{P}^{(1)}$} (p1)
            (p1) edge[bend left, above, sloped, anchor=south] node{$subsol$} (master)
            (master) edge[below, sloped, anchor=south] node{$\mathcal{P}^{(2^{n_p})}$} (pn)
            (pn) edge [bend right, above, sloped, anchor=south] node{$subsol$} (master);
    \end{tikzpicture}
    \caption{Visual example of the parallelization strategy for solving a system $\mathcal{P}$ on multicore architectures. Each $\mathcal{P}^{(i)}$ is a partially evaluated system. Once a core returns a solution, the \texttt{run.py} script appends to it the values of the fixture for that core. Here, $n_{p} = \lfloor \log_2 q \rfloor$ and $q$ is the amount of cores.} \label{fig:multicore_visual}
\end{figure}

\paragraph{Multicore.} Another optimization strategy is the use of multicore CPUs. In order to solve larger systems, a good solver would make use of as many of the resources available as possible. Through the \texttt{run.py} script, the solver can be spawned in a multicore context, wherein each core runs a separate \textit{instance} of the input system.

Say the CPU(s) of the system has (have) a combined $q$ cores available. Running 
$$
    n_{p} = \lfloor \log_2 q \rfloor
$$ 
solvers in parallel is possible by \textit{partially evaluating} the input system $\mathcal{P}$. With $n_{partial}$ variables, $2^{n_{p}}$ variable assignments are possible. Therefore, by fixing $n_{p}$ variables, $2^{n_{partial}}$ cores may receive their own partially evaluated system, i.e. an independent input system. That is, a partial evaluation would generate systems,
$$
    \mathcal{P}^{(0)}, \mathcal{P}^{(1)}, \dots \mathcal{P}^{(2^{n_{p}})},
$$
that can be solved independently. This idea is also described in \cref{sec:prereq:partial_eval}. If one of the $2^{n_{partial}}$ cores find a solution, the core can simply append the fixture of the $n_{p}$ variables to obtain a solution for $\mathcal{P}$.

Currently, the multicore operation is implemented directly in the \texttt{run.py} script, using Pythons built-in \texttt{multiprocess} library. Using this library for concurrency ensures that no problems with Python's infamous Global Interpreter Lock are met. However, the variables for the input system are fixed in Python, handing each fixed system to a separate process that then internally calls the \texttt{solve()} function from the shared library (either vectorized or standard, depending on what was compiled).

A visualization of the multicore implementation can be found in \cref{fig:multicore_visual}.

\paragraph{SIMD instructions.} As the target machines for this solver are x86-based, many SIMD instructions are available. In \cite{eurocrypt-2021-30841}, the memory-efficient Möbius transform is described alongside a theoretical optimization strategy. The idea for this strategy was to pre-compute multiple $\Tilde{\mathcal{P}_k}$ systems and interleave their respective evaluations of the $U$ polynomials with solution testing. This idea is somewhat mimicked with the use of SIMD instructions and \texttt{fes\_recover()}.

Using appropriate Make-flags (see \cref{sec:impl:compile}) the \texttt{mq.so} library may either include AVX or AVX2-based instructions (specifically as GCC intrinsics). Now, the vector registers available in modern x86 CPUs, are either 128 bits or 256 bits in size. These registers may contain different sizes of integer or floating-point data. For the solver here, integer data is of the most relevance.

\begin{figure}[t]
    \centering 
    \begin{tikzpicture}[
        % every node/.style={minimum height=2em}
    ]
    
        \matrix [
            matrix of math nodes,
            nodes={
                draw,
                sharp corners,
                minimum width=12mm,
                anchor=center,
            },
        ] (mat_const) {
            \Tilde{\mathcal{P}}^{(0)}_0 & \Tilde{\mathcal{P}}^{(0)}_1 & \Tilde{\mathcal{P}}^{(0)}_2 & \Tilde{\mathcal{P}}^{(0)}_3 & \Tilde{\mathcal{P}}^{(1)}_0 & \Tilde{\mathcal{P}}^{(1)}_1 & \Tilde{\mathcal{P}}^{(1)}_2 & \Tilde{\mathcal{P}}^{(1)}_3 \\
        };
        \node[left=3pt of mat_const-1-1] {$c$};
        \matrix [
            matrix of math nodes,
            nodes={
                draw,
                sharp corners,
                minimum width=12mm,
                anchor=center,
            },
            below=5mm of mat_const,
        ] (mat_lin1) {
            \Tilde{\mathcal{P}}^{(0)}_0 & \Tilde{\mathcal{P}}^{(0)}_1 & \Tilde{\mathcal{P}}^{(0)}_2 & \Tilde{\mathcal{P}}^{(0)}_3 & \Tilde{\mathcal{P}}^{(1)}_0 & \Tilde{\mathcal{P}}^{(1)}_1 & \Tilde{\mathcal{P}}^{(1)}_2 & \Tilde{\mathcal{P}}^{(1)}_3 \\
        };
        \node[left=3pt of mat_lin1-1-1] {$x_0$};
        \matrix [
            matrix of math nodes,
            nodes={
                draw,
                sharp corners,
                minimum width=12mm,
                anchor=center,
            },
            below=5mm of mat_lin1,
        ] (mat_lin2) {
            \Tilde{\mathcal{P}}^{(0)}_0 & \Tilde{\mathcal{P}}^{(0)}_1 & \Tilde{\mathcal{P}}^{(0)}_2 & \Tilde{\mathcal{P}}^{(0)}_3 & \Tilde{\mathcal{P}}^{(1)}_0 & \Tilde{\mathcal{P}}^{(1)}_1 & \Tilde{\mathcal{P}}^{(1)}_2 & \Tilde{\mathcal{P}}^{(1)}_3 \\
        };
        \node[left=3pt of mat_lin2-1-1] {$x_1$};
        \matrix [
            matrix of math nodes,
            nodes={
                draw,
                sharp corners,
                minimum width=12mm,
                anchor=center,
            },
            below=1cm of mat_lin2,
        ] (mat_quad) {
            \Tilde{\mathcal{P}}^{(0)}_0 & \Tilde{\mathcal{P}}^{(0)}_1 & \Tilde{\mathcal{P}}^{(0)}_2 & \Tilde{\mathcal{P}}^{(0)}_3 & \Tilde{\mathcal{P}}^{(1)}_0 & \Tilde{\mathcal{P}}^{(1)}_1 & \Tilde{\mathcal{P}}^{(1)}_2 & \Tilde{\mathcal{P}}^{(1)}_3 \\
        };
        \node[left=3pt of mat_quad-1-1] {$x_{n - 2}x_{n - 1}$};

        \path (mat_lin2) -- node[auto=false]{\textbf{\vdots}} (mat_quad);
        
        \draw [decorate,decoration={calligraphic brace,raise=5pt},thick] (mat_const-1-1.north west) --  (mat_const-1-1.north east) node[above=10pt, pos=0.5] {16 bits};
        
        \begin{scope}[on background layer]
            \draw [fill=red, fill opacity=0.5] (mat_quad-1-1.north west) rectangle (mat_quad-1-4.south east);
            \draw [fill=green, fill opacity=0.5] (mat_quad-1-5.north west) rectangle (mat_quad-1-8.south east);
            \draw [fill=red, fill opacity=0.5] (mat_lin2-1-1.north west) rectangle (mat_lin2-1-4.south east);
            \draw [fill=green, fill opacity=0.5] (mat_lin2-1-5.north west) rectangle (mat_lin2-1-8.south east);
            \draw [fill=red, fill opacity=0.5] (mat_const-1-1.north west) rectangle (mat_const-1-4.south east);
            \draw [fill=green, fill opacity=0.5] (mat_const-1-5.north west) rectangle (mat_const-1-8.south east);
            \draw [fill=red, fill opacity=0.5] (mat_lin1-1-1.north west) rectangle (mat_lin1-1-4.south east);
            \draw [fill=green, fill opacity=0.5] (mat_lin1-1-5.north west) rectangle (mat_lin1-1-8.south east);
        \end{scope}
    \end{tikzpicture}
    \caption{Visualization of how the $\Tilde{\mathcal{P}}^{(i)}_k$ sub-systems are parallelized in a 128-bit AVX register, using integer sizes of 16-bits ($n_1 + 1 \leq 16$). This case would fix 1 variable, creating two new systems $\mathcal{P}^{(0)}$ and $\mathcal{P}^{(1)}$, each with their sub-systems, $\Tilde{\mathcal{P}}^{(i)}_k$. One row above corresponds to how \texttt{poly\_vec\_t} types are used in the vectorized codebase. The structure for the derivative table entries is similar to a row above.} \label{fig:avx_parallel_vis}
\end{figure}

Since the \texttt{solve()} function internally sets 
$$
    n_1 = \lceil \frac{n}{5.4}\rceil,
$$
and the $\Tilde{\mathcal{P}_k}$ systems consist of $\ell = n_1 + 1$ polynomials, an input system of $m \leq 37$ can fit bit-sliced terms of $\Tilde{\mathcal{P}}_k$ into single bytes. For these system sizes it is possible to pack either $\frac{128}{8} = 16$, or $ \frac{256}{8} = 32$, bit-sliced terms of $\Tilde{\mathcal{P}_k}$s into a single AVX register. Likewise, for $\mathcal{P}$ with $37 < m \leq 64$, an AVX register can hold either $\frac{128}{16} = 8$ or $\frac{256}{16} = 16$ terms of $\Tilde{\mathcal{P}_k}$s in separate 16-bit integers inside the vector register. 

Given that the expected number of rounds to find a solution is 4 (shown in \cite{eurocrypt-2021-30841}), the vectorized version of the \texttt{solve()} function uses the AVX registers as follows: Say an AVX register can hold terms for $j$ sub-systems $\Tilde{\mathcal{P}_k}$. By fixing 
$$
    n_p = \log_2 \frac{j}{4}
$$ 
variables of $\mathcal{P}$, each partially evaluated version of $\mathcal{P}$ gets its own four vector indices, for the $\Tilde{\mathcal{P}_k}$ systems. That is, the procedure fixes $n_p$ variables, producing the systems
$$
    \mathcal{P}^{(0)}, \mathcal{P}^{(1)}, \dots \mathcal{P}^{(2^{n_{p}})}.
$$
Then, each round of \texttt{solve()} computes four $\Tilde{\mathcal{P}}^{(i)}_k$ systems for each fixed system $\mathcal{P}^{(i)}$ and stores them all in one AVX register. This way, AVX registers can hold a certain term for each bit-sliced system internally as integer data. This allows the procedure to operate in a lock-step manner on multiple systems at once, without having to synchronize between threads or processes. A visualization of this parallelization strategy can be seen in \cref{fig:avx_parallel_vis}.

For the most part, the procedure follows the likes of the \textit{standard} implementation described in \cref{sec:impl:c}, however, some parts may need explanation. In the setup of \texttt{solve()} in \texttt{src/c/vectorized/mq\_vectorized.c}, the procedure fixes the input system $\mathcal{P}$ and stores the fixed systems in new and smaller integer arrays
\clisting{src/c/vectorized/mq_vectorized.c}{134}{139}
which can be seen in the snippet above. The variable macro \texttt{FIXED\_VARS} is set depending on the Make flags (see \cref{sec:impl:compile}), but represents the number of variables fixed for the current setup. The variable \texttt{new\_n} is set to be 
\clisting{src/c/vectorized/mq_vectorized.c}{128}{128}
which then is used internally instead of the original \texttt{n} variable for most computations. Of course, \texttt{FIXED\_VARS} represents the value of $n_p$ from earlier, chosen through the flags given to Make at compile time.

The procedure \texttt{gen\_matrix()} is kept the same (\texttt{src/c/utils.c}), primarily to comply with the testing framework. However, instead of computing only one matrix in each round of \texttt{solve()}, the procedure computes one for each $\Tilde{\mathcal{P}}^{(i)}_k$ in the vector register. The \texttt{rand\_sys} variable, traditionally representing $\Tilde{\mathcal{P}_k}$, is however a bit different. Instead of \texttt{poly\_t *rand\_sys}, the generated systems are stored as \texttt{poly\_vec\_t *}:
\clisting{src/c/vectorized/mq_vectorized.c}{145}{145}
Also noticed the \texttt{aligned\_alloc} call. An effect of using AVX registers is that in any memory location storing vector values, the memory needs to be correctly aligned. Instructions do exist to work with unaligned memory, however, these are slower than their aligned counterparts.

The \texttt{fes\_recover()} is also different for the vectorized versions. The function declaration can still be found in \texttt{inc/fes.h}, but it looks a bit different:
\clisting{inc/fes.h}{44}{46} 
The procedure takes both the original system \texttt{poly\_t *system} (non-fixed) as well as the vector of $\Tilde{\mathcal{P}}^{(i)}_k$ systems. Also, instead of an array in \texttt{poly\_t *result}, the procedure uses the parameter to return a single \textit{actual} solution to $\mathcal{P}$.

Going into \texttt{src/c/vectorized/fes.c}, much of the code may seem similar to that explained in \cref{sec:impl:c}. Much of the logic is on an abstract level the same, but instead of using \texttt{poly\_t *} to represent systems, most procedures instead use \texttt{poly\_vec\_t *}. The various function-like macros prepended with \texttt{VEC\_} represent an abstraction layer over the AVX intrinsics used to work with AVX registers. Recall that each AVX register contains four rounds worth of sub-systems, for evaluations of $\mathcal{P}$ on some fixture. Therefore, snippets like 
\clisting[label={lst:c:vector_parity}]{src/c/vectorized/fes_vectorized.c}{364}{370}
display how the aforementioned ''lock-stepping'' works in practice. The non-vectorized version of the above snippet is
\clisting{src/c/standard/fes.c}{353}{357}
for which the differences between the vectorized and non-vectorized versions show. Both snippets are from \texttt{fes\_eval\_parity()} in the vectorized and non-vectorized versions, respectively. Since the vectorized version runs multiple bit-sliced systems in parallel during the execution, conditionals have to be handled differently. E.g. for each system in the vector \texttt{s->y}, in \cref{lst:c:vector_parity}, a combination of AVX \textit{masks} and \textit{blends} are used to mimic multiple parallel conditional checks at once. These principles are the same throughout \texttt{src/c/vectorized/fes\_vectorized.c}.

To quickly summarize the idea of AVX masks and blends: An AVX mask represents the evaluation of some logical statement in each of the vector elements, e.g. comparing equality between two vector registers would return a mask where the indices with \textit{equality} store all 1-bits and those with \textit{inequality} store all 0-bits. A use-case for such an AVX mask is \textit{blending}, in which elements between two vectors are blended depending on some specified mask. This blending can also be interpreted as a \textit{filtering} mechanism with a vector of ''defaults''.

At last, the biggest difference between the two codebases is how solutions, checking and processing, are handled. The snippet 
\clisting{src/c/vectorized/fes_vectorized.c}{448}{477}
shows how the vectorized codebase handles evaluations of $U$ polynomials. As an AVX register contains multiple $\Tilde{\mathcal{P}}^{(i)}_k$ systems it computes the evaluations of the $U$ polynomials in lock-step as well. Therefore, for each evaluation of the $U$ polynomials, the system may simply check if overlapping values exist in each group of four vector elements in the register. If an overlap is found, the procedure extracts all overlapping solutions directly from the register, constructs the solution(s) and evaluates on $\mathcal{P}$ directly. If a solution is found, the procedure may return. If no full evaluation on $\mathcal{P}$ succeeds, the procedure returns an error, which tells \texttt{solve()} to start a new round.

Because evaluations of $U$ the polynomials are computed and checked simultaneously, no large lists of solutions are stored. This will drastically affect memory consumption and entirely mitigates the need for storing solutions. The cost of this is that the procedure potentially skips some solutions as each round of \texttt{solve()} in \texttt{src/c/vectorized/mq\_vectorized.c} logically corresponds to computing four rounds in the \textit{standard} version and throwing away all potential solutions found if none was found in said group of four rounds. 

\subsection{C abstractions} \label{sec:impl:c_abstr}
The C codebases contain certain levels of abstractions, in order to make them more extendable. One example of this is the use of macros. Recall from previous subsections that many places in the C code, macro-like functions such as \texttt{INT\_IS\_ZERO}, \texttt{INT\_IDX}, or \texttt{GF2\_MUL} are called (\cref{lst:c:index}, \cref{lst:c:history_check} to give some example listings). These macros are used as an abstractional layer in order to hide the structure of the underlying \texttt{poly\_t} type. If the goal is to extend the codebase to support wider integer types, allowing for larger systems bit-sliced into integers, these macros help hide the operands used. This could be used in case the wider integer type does not support certain operations. E.g., GCC has support for 128-bit integers on target machines with wide enough integer modes, however, these do have limitations in certain areas and may therefore require workarounds that can be hidden using the aforementioned macros. The macros defined for integers can be found in \texttt{inc/mq\_uni.h}.

Likewise, the vectorized codebase hides many operations behind macros for the same reason. These macros can be found in \texttt{inc/mq\_vec.h} which internally makes use of either \texttt{inc/vec128\_config.h} or \texttt{inc/vec256\_config.h}. The latter two header files also include relevant macros for stating how many variables to fix given the Make flags used, the number of elements in a vector register (given the integer sizes stored in it), and other constants. Say the goal is to extend the codebase to use AVX512 as well, or future AVX (maybe even Intels AMX instructions): The process is a matter of creating a file similar to \texttt{inc/vec128\_config.h} or \texttt{inc/vec256\_config.h}, adding an appropriate conditional case in \texttt{inc/mq\_vec.h}, and finally running the code. Exactly which macros need to be present in the newly added vector-config header is described in \texttt{inc/mq\_vec.h}. 

Depending on how exotic the vector instruction set is, it may be necessary to add or change functionality in \texttt{src/c/vectorized/vector\_utils.h} as well. If it is simply a matter of adding support for a newer version of AVX, then the approach just described should be fine.

Ensuring that macros like \texttt{FIXED\_VARS} and \texttt{VECTOR\_ELEMENTS} are set correctly, ensures that the vectorized codebase is automatically set up, at compile time, for fixing the correct amount of variables and only storing four rounds for each fixed polynomial, as described in \cref{sec:impl:opt}.

\subsection{Testing the code}
The following subsection contains some brief notes on the testing methodology and how it was executed. For more on how to run and test different areas of the codebase, see the \texttt{README.md} file in the accompanying Git repository.

\subsubsection{SageMath}

For each of the procedures implemented in Python or SageMath, the accompanying test procedures can be found in the same file as the procedure being tested. For example, the tests related to \texttt{bruteforce()} and \texttt{fes\_eval()} can be found in \texttt{src/sage/fes.sage}, while tests related to \texttt{solve()}, \texttt{output\_potentials()} and \texttt{compute\_u\_values()} are found in \texttt{src/sage/dinur.sage}.

Since this SageMath prototype would eventually act as a reference point for the C implementation, the testing approach was to essentially create unit tests for select parts of the codebase. For procedures such as \texttt{output\_potentials()}, the testing methodology was to evaluate the $U$ polynomials in their entirety. The following snippet shows an example,
\pylisting{src/sage/dinur.sage}{118}{118}
The snippet above is directly computing the sums related to the $U_i$ polynomials ($i = 1, \dots n_1$). This testing strategy, where values for the theoretical constructs are explicitly computed and compared against the outputs of their target procedures, is repeated whenever possible. This way, the testing process is not bound to only run work with pre-computed results. In addition, the testing framework allows for generating multiple systems and storing any input system that triggers a fail in a test, so it may be reused later. A downside to this approach is of course that some of these theoretical constructs take quite a while to compute.

These tests can be executed using the \texttt{run.py} script with the \texttt{-t} flag, specifying what test should be run. To list all available tests, use the \texttt{-l} flag. Information about the \texttt{run.py} script can be found in the accompanying \texttt{README.md} file and partly in \cref{sec:impl:interface}.

\subsubsection{C code}

For the C implementation, there are different levels of tests. Either one may compile the \texttt{bin/test} binary, using the appropriate Make flags and targets (see \cref{sec:impl:compile}), or one may run tests using the shared library \texttt{bin/mq.so} (if compiled). In both cases, the results of the C implementations are compared against relevant reference points in the SageMath code implementations. This way, going from the unit tests for the SageMath code, the C code can be directly compared to the verified SageMath code. The test functions for the C code may also be run via the \texttt{run.py} script.

Running tests with the \texttt{bin/test} executable file, memory sanitizers and debugging information is enabled. These tests are used for testing procedures like the computation of the $\Tilde{\mathcal{P}}_k$ sub-systems and comparing it against the SageMath version. In general, these tests are fed relevant inputs via the SageMath code as well as the desired result(s) and checks against them internally in the executable. All these tests are found in \texttt{src/sage/dinur.sage} and contain a postfix of \texttt{\_SAN} in their function name.

The alternative is to test different functions using the \texttt{bin/mq.so} shared library. Other than testing for correctness, these tests also help test the bridge between the shared library and Python/SageMath. Like the tests for the SageMath code itself, these tests can be found in the related \texttt{.sage} files; tests for \texttt{fes()} and \texttt{bruteforce()} can be found in \texttt{fes.sage}, \texttt{fes\_recover()} in \texttt{src/sage/fes\_rec.sage}, etc. The tests related to the C codebase(s) all contain the character c in test names.

It could be argued here that more tests should exist, especially for the C codebase. Many new procedures were introduced in both the \textit{standard} and \textit{vectorized} codebases, implying that further testing of these individual parts should have taken place on a more granular level. 

\subsection{Interface for running the C code} \label{sec:impl:interface}
The C code was developed to be usable via multiple means. Once a compiled shared library is available, the code can either be loaded into other projects that support \texttt{.so} files, or it can be run as a complete solution via \texttt{run.py}. 

Running the solver as a script, an invocation without any flags results in a single-core solve routine using the version of the build that was specified at compile time (in essence; \textit{standard} or \textit{vectorized}). The invocation will either ask for a path to an MQ-challenge\footnote{\url{https://www.mqchallenge.org/}} style text file from which the system may be loaded, or for relevant parameters in order to generate the systems before solving. Giving the \texttt{-p} or \texttt{--parallelize} flag when invoking \texttt{run.py} allows the script to parallelize the solver by fixing variables according to how many CPU cores are present on the system. This last part was described in \cref{sec:impl:opt}.

Using the shared library on its own in an independent project is also quite straightforward. Although quite a few header files are present in the \texttt{inc/} folder, the most important one is \texttt{inc/mq.h}. If instead the goal is to use other parts of the codebase one may include \texttt{inc/fes.h} for FES-related declarations, or \texttt{inc/utils.h} for different utilities like evaluating polynomials, generating matrices or simply computing indices for the bit-sliced representation. The \texttt{inc/vector\_utils.h} header is for utilities for the vectorized implementations. Definitions and macros used throughout the codebase may be included via the \texttt{inc/mq\_config.h} file. At last, the benchmarking code can also be called on the shared library file. This provides the ability to hook in and read benchmarks directly in C code (from the global variables), and of course, call the benchmark procedure as a whole. Relevant benchmark declarations are stored in \texttt{inc/benchmark.h}. As the benchmark values are simply stored as global variables, it is not recommended to do much more than read the variables. 

Note, common for any function that takes a \texttt{poly\_t} array (or \texttt{poly\_vec\_t}) as input is that the stored system is expected to be bit-sliced, linearized, and (monomials) stored in \textit{graded lexicographic order}.

The C code can of course also be executed via the \texttt{bin/test} executable, which may be compiled with the accompanying Makefile. However, this executable is made to primarily work in tandem with tests in the SageMath code, therefore it is probably not of great interest to execute the solver this way.

\subsection{Compilation and compile-time parameters} \label{sec:impl:compile}
The accompanying Makefile can conform to multiple platforms using either vectorized instructions or building for machines with different register sizes. Building any of these different targets requires altering the \texttt{REGSIZE} flag, and/or the \texttt{INTSIZE} flag, when calling \texttt{make}. Setting \texttt{REGSIZE} to 8, 16, 32, or 64 means building the non-vectorized version, but regulates the integer sizes used to store the polynomials and solutions to the given width. Specifying 128 or 256 means that the build uses 128-bit or 256-bit registers, respectively. When specifying \texttt{REGSIZE} as one of the vector sizes, the \texttt{INTSIZE} flag controls the size of integers stored in these AVX vectors. The options for \texttt{INTSIZE} on vectorized builds is either \texttt{INTSIZE=8} or \texttt{INTSIZE=16}.

The default target creates the file \texttt{bin/mq.so}, ready for dynamic linking into other projects, optimized with \texttt{-O3}. The contents of this shared library are described in \cref{sec:impl:c}. Running \texttt{make tests} will create an executable \texttt{bin/test} with memory sanitizers and debug flags enabled. 

While compiling any of the targets, the makefile generates a few extra files as well. One file is \texttt{src/sage/.compile\_config}, ensuring better interoperability between the SageMath code and the C code. A more prominent file is the \texttt{inc/binom.h} file generated. The \texttt{inc/binom.h} file is a header file containing a lookup table \textit{of sufficient size} alongside the necessary macros to do lookups quickly. This lookup table is generated by the Makefile which internally calls the \texttt{binom.py} script and saves the output in \texttt{inc/binom.h}. The lookup table is used by the indexing function \texttt{monomial\_to\_index()}.


\newpage