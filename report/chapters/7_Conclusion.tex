\chapter{Conclusion} \label{sec:concl}

This thesis aimed to implement and identify key performance factors in the polynomial-method algorithm of \cite{eurocrypt-2021-30841}. In this paper, the algorithm is advertised as having exponential speedup over exhaustive search, making it an interesting subject for practical implementations. The path between theory and practice can at times be extensive, and therefore a part of the \textit{evaluation}-goal of the thesis was the identification of strongly theoretical areas that need extra attention when implemented in practice.

One area of interest was the interpolation and evaluation of polynomials, used in one of the sub-procedures of \cite{eurocrypt-2021-30841}. As an alternative to using the Möbius transform, an algorithm based on the principles of the Fast Exhaustive Search procedure (FES) from \cite{ches-2010-23990} was introduced and implemented (\cref{sec:ext}). Instead of pursuing a variant of Dinur's algorithm using the Möbius transform, this new variant was used instead. Choosing to go with an alternate variant of Dinur's algorithm was based on the fact that many FES implementations has seen the light of day, giving more references for real implementations than when compared to the Möbius transform. Of course, the Möbius transform has seen implementations from both \cite{cryptoeprint:2022/1412} and \cite{joux2009algorithmic}, however, Dinur's algorithm required a modified variant with less reference material to go by.

Another effect of choosing the FES-based approach for interpolation and evaluation was to better enable optimizations that would make use of the resources present in modern CPUs. One such optimization uses SIMD instructions through the AVX instruction set(s). This led to the codebase of the thesis being divided into three parts; (I) A SageMath prototype for testing the more algorithmic aspects of \cite{eurocrypt-2021-30841}. (II) A so-called \textit{standard} implementation in C of \cite{eurocrypt-2021-30841}, that sought to do some optimizations but kept its relation to the reference material clear. (III) An implementation in C using AVX instructions and registers, trying to optimize as much as the thesis deadline allowed. The two C implementations were also both able to run on multicore systems, using the included Python script to run the solver.

The key points for performance evaluations are timing and memory. Especially memory consumption was proven to be extensive in the original paper \cite{eurocrypt-2021-30841}. The comparisons found that certain memory optimizations of the C implementations were quite welcome and certain cases saw a factor four decrease in memory consumption, from the theoretically derived values to the practically measured ones. These findings also showed that certain theoretic bounds did not hold in the implementations, in terms of the number of solutions that needed to be stored. An even stronger memory optimization was found via the vectorized AVX implementation, as this implementation managed to mitigate storing large amounts of potential solutions by implementing a lock-step parallel approach. At last, the implementations were compared to a simple implementation of the barebones FES procedure for quadratic systems. This comparison strengthened the reasons for trying to further optimize the implementation, in order to be competitive in real-world scenarios, and claim the speedup it obtained in theoretical analyses. 

In general, although the practical findings of this thesis did not prove as optimistic as the theoretical ones in \cite{eurocrypt-2021-30841}, they did show some relevant areas. This should enable future implementations, be they extensions to this or standalone, to more easily identify problems and their solutions that stem from converting theory to practice. Some of these elements can also be used for related polynomial-method algorithms that \cite{eurocrypt-2021-30841} used for inspiration.

\paragraph{Future work.} In order to make the implementations from this thesis more competitive, multiple areas may be looked into. Of course, a direct comparison between an optimized Möbius transform implementation and the FES-based recovery explained in \cref{sec:ext} would be necessary. On this note, comparing and implementing the \textit{memory-efficient Möbius transform} to these would also be of great interest. Also, although the internal FES implementation, i.e. \texttt{fes\_eval\_parity()}, was optimized to some extent it was never near the likes of \cite{ches-2010-23990} and \cite{cryptoeprint:2013/436}. Therefore, optimizing this procedure more to the likes of those papers, possibly alongside the use of \textit{monotonic Gray codes}, would yield better data on how the algorithm performs in reality.

An alternative to implementing home-grown Möbius transforms and FES procedures, a library was published alongside \cite{cryptoeprint:2022/1412}. It would be interesting to see this library work in tandem with the rest of a codebase like the one in this thesis, although they may not be as specialized as the ones from \cite{ches-2010-23990} and \cite{cryptoeprint:2013/436}.

Now, the rest of the codebase(s) for this thesis are neither perfect. Some future work should be dedicated to understanding why such a large deviation in stored candidate solutions occur (mentioned in \cref{sec:eval:mem}), compared to the theoretically expected amounts. This would of course also help increase performance for both C variants, while minimizing memory usage. In terms of timings, alternatives for the indexing operation of \texttt{fes\_recover()} and \texttt{fes\_recover\_vectorized()} could also be interesting, as this helps bring down the overall time spent on FES-based recovery. 

For parallelization, altering the multicore handling to be exclusively C would likely help a lot too. This way, using a library like OpenMP\footnote{\url{https://www.openmp.org/}}, the fixation of variables could be handled at once, w.r.t. the vectorized implementation. Currently, the fixation of variables occurs at two levels, once when multiple cores need an independent system and once when filling entries in the AVX vectors. On this note, introducing larger integer registers for the standard implementation, or more compactly packing systems into AVX registers, could also be an interesting addition. Currently, the vectorized implementation risks wasting a non-negligible amount of bits. E.g. for $\ell = 9$, the vectorized implementation (using 256-bit registers) would store $\Tilde{\mathcal{P}}^{(i)}_k$s in 16 16-bit integers in the 256-bit AVX register where each integer only actually uses 9 bits. By compacting these $\Tilde{\mathcal{P}_k}$ more tightly in the vector register, the implementation may be able to store more rounds or fixed systems. This would also allow for a replacement of unsigned integers as the underlying data structure, for bit-slicing polynomials in the standard implementation.